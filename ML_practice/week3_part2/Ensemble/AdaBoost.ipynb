{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5cac1e1",
   "metadata": {},
   "source": [
    "AdaBoost is provided via the [AdaBoostRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html) \n",
    "and [AdaBoostClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html)  classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6a3917",
   "metadata": {},
   "source": [
    "# AdaBoost for Classification\n",
    "\n",
    "In this section, we will look at using AdaBoost for a classification problem.\n",
    "\n",
    "First, we can use the [make_classification()](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) function to create a synthetic binary classification problem with 1,000 examples and 20 input features.\n",
    "\n",
    "The complete example is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c671ff0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20) (1000,)\n"
     ]
    }
   ],
   "source": [
    "# test classification dataset\n",
    "from sklearn.datasets import make_classification\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=6)\n",
    "# summarize the dataset\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d50ba1",
   "metadata": {},
   "source": [
    "Next, we can evaluate an AdaBoost algorithm on this dataset.\n",
    "\n",
    "We will evaluate the model using [repeated stratified k-fold cross-validation](https://machinelearningmastery.com/k-fold-cross-validation/), with three repeats and 10 folds. We will report the mean and standard deviation of the accuracy of the model across all repeats and folds. Running the example below reports the mean and standard deviation accuracy of the model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03af89e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.806 (0.041)\n"
     ]
    }
   ],
   "source": [
    "# evaluate adaboost algorithm for classification\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=6)\n",
    "# define the model\n",
    "model = AdaBoostClassifier()\n",
    "# evaluate the model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017cf691",
   "metadata": {},
   "source": [
    "We can also use the AdaBoost model as a final model and make predictions for classification.\n",
    "\n",
    "First, the AdaBoost ensemble is fit on all available data, then the predict() function can be called to make predictions on new data.\n",
    "\n",
    "The example below demonstrates this on our binary classification dataset.Running the example below fits the AdaBoost ensemble model on the entire dataset and is then used to make a prediction on a new row of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c1bca0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: 0\n"
     ]
    }
   ],
   "source": [
    "# make predictions using adaboost for classification\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=42)\n",
    "# define the model\n",
    "model = AdaBoostClassifier()\n",
    "# fit the model on the whole dataset\n",
    "model.fit(X, y)\n",
    "# make a single prediction\n",
    "row = [[-3.47224758,1.95378146,0.04875169,-0.91592588,-3.54022468,1.96405547,-7.72564954,-2.64787168,-1.81726906,-1.67104974,2.33762043,-4.30273117,0.4839841,-1.28253034,-10.6704077,-0.7641103,-3.58493721,2.07283886,0.08385173,0.91461126]]\n",
    "yhat = model.predict(row)\n",
    "print('Predicted Class: %d' % yhat[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053d5095",
   "metadata": {},
   "source": [
    "# AdaBoost for Regression\n",
    "\n",
    "In this section, we will look at using AdaBoost for a regression problem.\n",
    "\n",
    "First, we can use the [make_regression()](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html) function to create a synthetic regression problem with 1,000 examples and 20 input features.\n",
    "\n",
    "The complete example is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94839412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20) (1000,)\n"
     ]
    }
   ],
   "source": [
    "# test regression dataset\n",
    "from sklearn.datasets import make_regression\n",
    "# define dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=20, n_informative=15, noise=0.1, random_state=6)\n",
    "# summarize the dataset\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f5f3dd",
   "metadata": {},
   "source": [
    "Next, we can evaluate an AdaBoost algorithm on this dataset.\n",
    "\n",
    "As we did with the last section, we will evaluate the model using repeated k-fold cross-validation, with three repeats and 10 folds. We will report the mean absolute error (MAE) of the model across all repeats and folds. The scikit-learn library makes the MAE negative so that it is maximized instead of minimized. This means that larger negative MAE are better and a perfect model has a MAE of 0.\n",
    "\n",
    "Running the example below reports the mean and standard deviation accuracy of the adaboost regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69637d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: -72.694 (3.812)\n"
     ]
    }
   ],
   "source": [
    "# evaluate adaboost ensemble for regression\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "# define dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=20, n_informative=15, noise=0.1, random_state=6)\n",
    "# define the model\n",
    "model = AdaBoostRegressor()\n",
    "# evaluate the model\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# report performance\n",
    "print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649dc887",
   "metadata": {},
   "source": [
    "We can also use the AdaBoost model as a final model and make predictions for regression.\n",
    "\n",
    "First, the AdaBoost ensemble is fit on all available data, then the predict() function can be called to make predictions on new data.\n",
    "\n",
    "Running the example below fits the AdaBoost ensemble model on the entire dataset and is then used to make a prediction on a new row of data, as we might when using the model in an application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97b0e8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: -43\n"
     ]
    }
   ],
   "source": [
    "# adaboost ensemble for making predictions for regression\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "# define dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=20, n_informative=15, noise=0.1, random_state=6)\n",
    "# define the model\n",
    "model = AdaBoostRegressor()\n",
    "# fit the model on the whole dataset\n",
    "model.fit(X, y)\n",
    "# make a single prediction\n",
    "row = [[1.20871625,0.88440466,-0.9030013,-0.22687731,-0.82940077,\n",
    "        -1.14410988,1.26554256,-0.2842871,1.43929072,0.74250241,\n",
    "        0.34035501,0.45363034,0.1778756,-1.75252881,-1.33337384,\n",
    "        -1.50337215,-0.45099008,0.46160133,0.58385557,-1.79936198]]\n",
    "yhat = model.predict(row)\n",
    "print('Prediction: %d' % yhat[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1252b120",
   "metadata": {},
   "source": [
    "# AdaBoost Hyperparameters\n",
    "\n",
    "In this section, we will take a closer look at some of the hyperparameters you should consider tuning for the AdaBoost ensemble and their effect on model performance.\n",
    "\n",
    "## Explore Number of Trees\n",
    "\n",
    "An important hyperparameter for AdaBoost algorithm is the number of decision trees used in the ensemble.\n",
    "\n",
    "Recall that each decision tree used in the ensemble is designed to be a weak learner. That is, it has skill over random prediction, but is not highly skillful. As such, one-level decision trees are used, called decision stumps.\n",
    "\n",
    "The number of trees added to the model must be high for the model to work well, often hundreds, if not thousands.\n",
    "\n",
    "The number of trees can be set via the “n_estimators” argument and defaults to 50.\n",
    "\n",
    "The example below explores the effect of the number of trees with values between 10 to 5,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fef228a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">10 0.773 (0.039)\n",
      ">50 0.806 (0.041)\n",
      ">100 0.801 (0.032)\n",
      ">500 0.793 (0.028)\n",
      ">1000 0.791 (0.032)\n",
      ">5000 0.783 (0.031)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# explore adaboost ensemble number of trees effect on performance\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "\tX, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=6)\n",
    "\treturn X, y\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\t# define number of trees to consider\n",
    "\tn_trees = [10, 50, 100, 500, 1000, 5000]\n",
    "\tfor n in n_trees:\n",
    "\t\tmodels[str(n)] = AdaBoostClassifier(n_estimators=n)\n",
    "\treturn models\n",
    "\n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "\t# define the evaluation procedure\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\t# evaluate the model and collect the results\n",
    "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\treturn scores\n",
    "\n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "\t# evaluate the model\n",
    "\tscores = evaluate_model(model, X, y)\n",
    "\t# store the results\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\t# summarize the performance along the way\n",
    "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810a13d8",
   "metadata": {},
   "source": [
    "Running the example first reports the mean accuracy for each configured number of decision trees.\n",
    "\n",
    "In this case, we can see that that performance improves on this dataset until about 50 trees and declines after that. This might be a sign of the ensemble overfitting the training dataset after additional trees are added.\n",
    "\n",
    "A box and whisker plot is created for the distribution of accuracy scores for each configured number of trees.\n",
    "We can see the general trend of model performance and ensemble size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3d5f63",
   "metadata": {},
   "source": [
    "## Explore Depth\n",
    "\n",
    "A decision tree with one level is used as the weak learner by default.\n",
    "\n",
    "We can make the models used in the ensemble less weak (more skillful) by increasing the depth of the decision tree.\n",
    "\n",
    "The example below explores the effect of increasing the depth of the [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) weak learner on the AdBoost ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa872a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1 0.806 (0.041)\n",
      ">2 0.863 (0.029)\n",
      ">3 0.870 (0.027)\n",
      ">4 0.899 (0.035)\n",
      ">5 0.912 (0.030)\n",
      ">6 0.925 (0.024)\n",
      ">7 0.931 (0.022)\n",
      ">8 0.933 (0.021)\n",
      ">9 0.926 (0.022)\n",
      ">10 0.933 (0.022)\n",
      ">11 0.888 (0.069)\n",
      ">12 0.815 (0.056)\n",
      ">13 0.806 (0.032)\n",
      ">14 0.803 (0.039)\n",
      ">15 0.799 (0.037)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# explore adaboost ensemble tree depth effect on performance\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "\tX, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=6)\n",
    "\treturn X, y\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\t# explore depths from 1 to 15\n",
    "\tfor i in range(1,16):\n",
    "\t\t# define base model\n",
    "\t\tbase = DecisionTreeClassifier(max_depth=i)\n",
    "\t\t# define ensemble model\n",
    "\t\tmodels[str(i)] = AdaBoostClassifier(base_estimator=base)\n",
    "\treturn models\n",
    "\n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "\t# define the evaluation procedure\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\t# evaluate the model and collect the results\n",
    "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\treturn scores\n",
    "\n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "\t# evaluate the model\n",
    "\tscores = evaluate_model(model, X, y)\n",
    "\t# store the results\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\t# summarize the performance along the way\n",
    "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17398491",
   "metadata": {},
   "source": [
    "Running the example first reports the mean accuracy for each configured weak learner tree depth.\n",
    "we can see that that performance improves on this dataset till depth = 10 and declines after that. This might be a sign of the ensemble overfitting the training dataset after too much increase in depth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85b016b",
   "metadata": {},
   "source": [
    "## Explore Learning Rate\n",
    "\n",
    "AdaBoost also supports a learning rate that controls the contribution of each model to the ensemble prediction.\n",
    "\n",
    "This is controlled by the “learning_rate” argument and by default is set to 1.0 or full contribution. Smaller or larger values might be appropriate depending on the number of models used in the ensemble. There is a balance between the contribution of the models and the number of trees in the ensemble.\n",
    "\n",
    "More trees may require a smaller learning rate; fewer trees may require a larger learning rate. It is common to use values between 0 and 1 and sometimes very small values to avoid overfitting such as 0.1, 0.01 or 0.001.\n",
    "\n",
    "The example below explores learning rate values between 0.1 and 2.0 in 0.1 increments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0e13e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">0.100 0.767 (0.049)\n",
      ">0.200 0.786 (0.042)\n",
      ">0.300 0.802 (0.040)\n",
      ">0.400 0.798 (0.037)\n",
      ">0.500 0.805 (0.042)\n",
      ">0.600 0.795 (0.031)\n",
      ">0.700 0.799 (0.035)\n",
      ">0.800 0.801 (0.033)\n",
      ">0.900 0.805 (0.032)\n",
      ">1.000 0.806 (0.041)\n",
      ">1.100 0.801 (0.037)\n",
      ">1.200 0.800 (0.030)\n",
      ">1.300 0.799 (0.041)\n",
      ">1.400 0.793 (0.041)\n",
      ">1.500 0.790 (0.040)\n",
      ">1.600 0.775 (0.034)\n",
      ">1.700 0.767 (0.054)\n",
      ">1.800 0.768 (0.040)\n",
      ">1.900 0.736 (0.047)\n",
      ">2.000 0.682 (0.048)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# explore adaboost ensemble learning rate effect on performance\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import arange\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "\tX, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=6)\n",
    "\treturn X, y\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\t# explore learning rates from 0.1 to 2 in 0.1 increments\n",
    "\tfor i in arange(0.1, 2.1, 0.1):\n",
    "\t\tkey = '%.3f' % i\n",
    "\t\tmodels[key] = AdaBoostClassifier(learning_rate=i)\n",
    "\treturn models\n",
    "\n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "\t# define the evaluation procedure\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\t# evaluate the model and collect the results\n",
    "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\treturn scores\n",
    "\n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "\t# evaluate the model\n",
    "\tscores = evaluate_model(model, X, y)\n",
    "\t# store the results\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\t# summarize the performance along the way\n",
    "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.xticks(rotation=45)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015e0325",
   "metadata": {},
   "source": [
    "Running the example first reports the mean accuracy for each configured learning rate.\n",
    "A box and whisker plot is created for the distribution of accuracy scores for each configured learning rate.\n",
    "\n",
    "In this case, we can see similar values between 0.5 to 1.0 and a decrease in model performance after that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735e88b2",
   "metadata": {},
   "source": [
    "## Explore Alternate Algorithm\n",
    "\n",
    "The default algorithm used in the ensemble is a decision tree, although other algorithms can be used.\n",
    "\n",
    "The intent is to use very simple models, called weak learners. Also, the scikit-learn implementation requires that any models used must also support weighted samples, as they are how the ensemble is created by fitting models based on a weighted version of the training dataset.\n",
    "\n",
    "The base model can be specified via the “base_estimator” argument. The base model must also support predicting probabilities or probability-like scores in the case of classification. If the specified model does not support a weighted training dataset, you will see an error message as follows:\n",
    "\n",
    "ValueError: KNeighborsClassifier doesn't support sample_weight.\n",
    "\n",
    "One example of a model that supports a weighted training is the logistic regression algorithm.\n",
    "\n",
    "The example below demonstrates an AdaBoost algorithm with a [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) weak learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27993a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.794 (0.032)\n"
     ]
    }
   ],
   "source": [
    "# evaluate adaboost algorithm with logistic regression weak learner for classification\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=6)\n",
    "# define the model\n",
    "model = AdaBoostClassifier(base_estimator=LogisticRegression())\n",
    "# evaluate the model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d8e98a",
   "metadata": {},
   "source": [
    "Running the example reports the mean and standard deviation accuracy of the model.\n",
    "\n",
    "In this case, we can see the AdaBoost ensemble with a logistic regression weak model achieves a classification accuracy of about 79 percent on this test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b194838d",
   "metadata": {},
   "source": [
    "## Grid Search AdaBoost Hyperparameters\n",
    "\n",
    "AdaBoost can be challenging to configure as the algorithm as many key hyperparameters that influence the behavior of the model on training data and the hyperparameters interact with each other.\n",
    "\n",
    "As such, it is a good practice to use a search process to discover a configuration of the model hyperparameters that works well or best for a given predictive modeling problem. Popular search processes include a random search and a grid search.\n",
    "\n",
    "In this section we will look at grid searching common ranges for the key hyperparameters for the AdaBoost algorithm that you can use as starting point for your own projects. This can be achieving using the [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) class and specifying a dictionary that maps model hyperparameter names to the values to search.\n",
    "\n",
    "In this case, we will grid search two key hyperparameters for AdaBoost: the number of trees used in the ensemble and the learning rate. We will use a range of popular well performing values for each hyperparameter.\n",
    "\n",
    "Each configuration combination will be evaluated using repeated k-fold cross-validation and configurations will be compared using the mean score, in this case, classification accuracy.\n",
    "\n",
    "The complete example of grid searching the key hyperparameters of the AdaBoost algorithm on our synthetic classification dataset is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24a495e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.813667 using {'learning_rate': 0.1, 'n_estimators': 500}\n",
      "0.646333 (0.036376) with: {'learning_rate': 0.0001, 'n_estimators': 10}\n",
      "0.646667 (0.036545) with: {'learning_rate': 0.0001, 'n_estimators': 50}\n",
      "0.646667 (0.036545) with: {'learning_rate': 0.0001, 'n_estimators': 100}\n",
      "0.647000 (0.038136) with: {'learning_rate': 0.0001, 'n_estimators': 500}\n",
      "0.646667 (0.036545) with: {'learning_rate': 0.001, 'n_estimators': 10}\n",
      "0.647000 (0.038136) with: {'learning_rate': 0.001, 'n_estimators': 50}\n",
      "0.654333 (0.045511) with: {'learning_rate': 0.001, 'n_estimators': 100}\n",
      "0.672667 (0.046543) with: {'learning_rate': 0.001, 'n_estimators': 500}\n",
      "0.648333 (0.042197) with: {'learning_rate': 0.01, 'n_estimators': 10}\n",
      "0.671667 (0.045613) with: {'learning_rate': 0.01, 'n_estimators': 50}\n",
      "0.715000 (0.053213) with: {'learning_rate': 0.01, 'n_estimators': 100}\n",
      "0.767667 (0.045948) with: {'learning_rate': 0.01, 'n_estimators': 500}\n",
      "0.716667 (0.048876) with: {'learning_rate': 0.1, 'n_estimators': 10}\n",
      "0.767000 (0.049271) with: {'learning_rate': 0.1, 'n_estimators': 50}\n",
      "0.784667 (0.042874) with: {'learning_rate': 0.1, 'n_estimators': 100}\n",
      "0.813667 (0.032092) with: {'learning_rate': 0.1, 'n_estimators': 500}\n",
      "0.773333 (0.038759) with: {'learning_rate': 1.0, 'n_estimators': 10}\n",
      "0.806333 (0.040701) with: {'learning_rate': 1.0, 'n_estimators': 50}\n",
      "0.801000 (0.032491) with: {'learning_rate': 1.0, 'n_estimators': 100}\n",
      "0.792667 (0.027560) with: {'learning_rate': 1.0, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "# example of grid searching key hyperparameters for adaboost on a classification dataset\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=6)\n",
    "# define the model with default hyperparameters\n",
    "model = AdaBoostClassifier()\n",
    "# define the grid of values to search\n",
    "grid = dict()\n",
    "grid['n_estimators'] = [10, 50, 100, 500]\n",
    "grid['learning_rate'] = [0.0001, 0.001, 0.01, 0.1, 1.0]\n",
    "# grid['max_depth'] = [range(1,11)]\n",
    "# define the evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define the grid search procedure\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy')\n",
    "# execute the grid search\n",
    "grid_result = grid_search.fit(X, y)\n",
    "# summarize the best score and configuration\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# summarize all scores that were evaluated\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2afc63",
   "metadata": {},
   "source": [
    "Running the example many take a while. At the end of the run, the configuration that achieved the best score is reported first, followed by the scores for all other configurations that were considered.\n",
    "\n",
    "In this case, we can see that a configuration with 500 trees and a learning rate of 0.1 performed the best with a classification accuracy of about 81.3 percent.\n",
    "\n",
    "The model may perform even better with more trees such as 1,000 or 5,000 although these configurations were not tested in this case to ensure that the grid search completed in a reasonable time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c59bc3",
   "metadata": {},
   "source": [
    "## Additional Resources :\n",
    "\n",
    "- https://machinelearningmastery.com/boosting-and-adaboost-for-machine-learning/\n",
    "\n",
    "- [A desicion-theoretic generalization of on-line learning and an application to boosting](https://link.springer.com/chapter/10.1007/3-540-59119-2_166)\n",
    "\n",
    "- [multiclass adaboost](https://www.intlpress.com/site/pub/pages/journals/items/sii/content/vols/0002/0003/a008/)\n",
    "\n",
    "- https://en.wikipedia.org/wiki/AdaBoost\n",
    "\n",
    "- [Improved Boosting Algorithms Using Confidence-rated Predictions](https://link.springer.com/article/10.1023/A:1007614523901)\n",
    "\n",
    "- [Explaining AdaBoost](https://link.springer.com/chapter/10.1007/978-3-642-41136-6_5)\n",
    "\n",
    "- [Tuning the hyper-parameters of an estimator using GridSearchCV](https://scikit-learn.org/stable/modules/grid_search.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb1776a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
