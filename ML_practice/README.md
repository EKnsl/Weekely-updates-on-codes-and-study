## Week1

Date : 19/05/2022

https://ml.howtocode.dev/

[ML basics(Lec 1.1 to 2.3 of the playlist)](https://www.youtube.com/playlist?list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN)

---------------------------------------------------------------------------------------------------------
Date : 20/05/2022

[Linear Regression](https://github.com/mhuzaifadev/mlzero_to_hero/tree/main/04_Simple%20_Linear_Regression)

-----------------------------------------------------------------------------------------------------------
Date : 23/05/2022

[lec 2.4 to 3.4 (Linear Regression with one variable and Linear Algebra upto matrix matrix multiplication)](https://www.youtube.com/playlist?list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN)

Additional : 

[ML intro](https://ml.howtocode.dev/)

[why matrix multiplication is not commutative i.e order matters](https://www.quora.com/Why-is-the-multiplication-of-matrices-not-a-commutative-property-so-that-AB-neq-BA)

----------------------------------------------------------------------------------------------------------

Date : 24/05/2022

[Linear Algebra review](https://towardsdatascience.com/linear-algebra-for-machine-learning-22f1d8aea83c)

[Lec 3.4 to 3.6(Linear Algebra) and Lecture 4.1 â€” Linear Regression With Multiple Variables-(Multiple Features)](https://www.youtube.com/playlist?list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN)

[Multiple Linear Regreassion notebook with startup data](https://github.com/mhuzaifadev/mlzero_to_hero/tree/main/05%20Multiple%20Linear%20Regression)

additional resources : 

Example of using categorical features : [Multiple Linear Regression: A quick Introduction](https://www.askpython.com/python/examples/multiple-linear-regression)

------------------------------------------------------------------------------------------------------------------------------------------

Date : 25/05/2022

Linear Regression with Multiple Variable: [Lecture 4.1 - 4.7 of this playlist.](https://www.youtube.com/watch?v=PPLop4L2eGk&list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN)

Logistic Reggression notebook with titanic data

additional resources :
[Why One-Hot Encode Data in Machine Learning?](https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning)

[Use ColumnTransformer to apply different preprocessing to different columns](https://www.youtube.com/watch?v=NGq8wnH5VSo)

[How column Transformers work](https://www.analyticsvidhya.com/blog/2021/05/understanding-column-transformer-and-machine-learning-pipelines/)

------------------------------------------------------------------------------------------------------------------------------------------------------

Date : 26/05/2022

* ## Practise Logistic Regression

    [My Logistic Regression Notebook](https://github.com/EKnsl/Weekely-updates-on-codes-and-study/blob/main/ML_practice/week1_ML_%20Intro_and_supervised_learing/code/Logistic_Regression.ipynb)

    * Prediction of survival with titanic dataset using Logistic regression 

    * Performance evaluation using accuracy precison, recall and f1 score

    related resources : 

    https://datascienceplus.com/logistic-regression-with-python-using-titanic-data/

    [kaggle notenook](https://www.kaggle.com/code/mnassrib/titanic-logistic-regression-with-python/notebook)

    [Feature Selection Techniques for regression](https://machinelearningmastery.com/feature-selection-for-regression-data/)

    -------------------------------------------------------------------------------------------------------------------------------------

Date : 30/05/2022

* ## Logistic Regression Basic concepts

    * Learnt about

        * Logistic function  
        
        * non-linear decision boundaries

        * A better cost function than sqaured error for classification with non linear decision boundary
         
        * Some optimization algorithms that often converge faster than Gradiant descent (according to Andrew N.G):
            * [Conjugate Gradient Descent](https://ikuz.eu/machine-learning-and-computer-science/the-concept-of-conjugate-gradient-descent-in-python/)
            
            * [BFGS](https://machinelearningmastery.com/bfgs-optimization-in-python/)
            
            * L-BFGS : 
            [How L-BFGS works](https://stats.stackexchange.com/questions/284712/how-does-the-l-bfgs-work),
            [L-BFGS method basics with python code](https://www.earthinversion.com/techniques/the-L-BFGS-optimization-method/)

        * One vs rest or One vs all for multiclass classification (choose 1 class from k classes)
            
            [One-vs-Rest and One-vs-One for Multi-Class Classification](https://machinelearningmastery.com/one-vs-rest-and-one-vs-one-for-multi-class-classification/ )
            
            [Logistic regression  Multiclass - One-vs-rest classification](https://www.youtube.com/watch?v=EYXSve6T5BU)
            
            [Logistic Regression Mutliclass Classification(OneVsRest)](https://www.youtube.com/watch?v=V8fS0T_ktn4)

    * Completed [Lecture 6.1 - 6.7 of this playlist.](https://www.youtube.com/playlist?list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN)

    --------------------------------------------------------------------------------------------------------------------------------
Date : 31/05/2022

* ## Study conditional probability and Naive Bayes
    [Naive Bayes practice](https://github.com/EKnsl/Weekely-updates-on-codes-and-study/tree/main/ML_practice/week2_Supervised_Learning/Naive%20Bayes)
    
    