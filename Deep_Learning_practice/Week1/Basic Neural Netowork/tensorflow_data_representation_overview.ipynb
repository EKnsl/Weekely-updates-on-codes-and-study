{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe14a7f7",
   "metadata": {},
   "source": [
    "# Brief illustration of how data is stored in Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caaf7c6d",
   "metadata": {},
   "source": [
    "Scaler : 0 dimensional tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "819f197c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(12)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.array(12)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0ace26e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1ddcf0",
   "metadata": {},
   "source": [
    "1 dimensional array : 1 dimensional tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8868f6a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([12, 3, 6, 14])\n",
    "X.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3828e052",
   "metadata": {},
   "source": [
    "matrix or 2D array : 2 dimensional tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73e8a5ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(\n",
    "    [\n",
    "        [1,2,3],\n",
    "        [4,5,6],\n",
    "        [7,8,9],\n",
    "        [10,11,12]\n",
    "    ]\n",
    ")\n",
    "\n",
    "X.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d671ad99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-26 11:53:13.463309: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-05-26 11:53:13.465890: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-26 11:53:13.465897: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9efe993e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor1 :  tf.Tensor([2 2], shape=(2,), dtype=int32)\n",
      "Shape of tensor2 :  tf.Tensor([3 2], shape=(2,), dtype=int32)\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tensor1 = tf.constant([[3,2], \n",
    "                      [5,2]])\n",
    "\n",
    "tensor2 = tf.constant([[3,2], \n",
    "                       [5,2],\n",
    "                       [5,2]\n",
    "                      ])\n",
    "# tensor.ndim\n",
    "print(\"Shape of tensor1 : \" , tf.shape(tensor1) )\n",
    "print(\"Shape of tensor2 : \" , tf.shape(tensor2) )\n",
    "# print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94add2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[3 2]\n",
      " [5 2]\n",
      " [5 2]], shape=(3, 2), dtype=int32)\n",
      "(3, 2)\n",
      "[Dimension(3), Dimension(2)]\n"
     ]
    }
   ],
   "source": [
    "print(tensor2)\n",
    "print(tensor2.get_shape())\n",
    "print(tensor2.shape.dims )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9cf7f520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[18, 76,  5, 92,  7],\n",
       "        [17, 66, 65, 50, 25],\n",
       "        [18, 38, 13, 70, 25],\n",
       "        [59, 42, 44, 14, 68]],\n",
       "\n",
       "       [[37, 52, 26, 25, 18],\n",
       "        [19, 15, 69, 62, 21],\n",
       "        [86, 49, 85, 61, 84],\n",
       "        [27, 44, 98, 15, 13]],\n",
       "\n",
       "       [[32, 36, 70, 30,  5],\n",
       "        [44, 12, 29,  2, 11],\n",
       "        [23, 55, 72, 22, 71],\n",
       "        [26, 78, 66, 47, 94]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_3d = np.random.randint(0, 100, size=(3, 4, 5))\n",
    "arr_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6e0043d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4, 5), dtype=int64, numpy=\n",
       "array([[[18, 76,  5, 92,  7],\n",
       "        [17, 66, 65, 50, 25],\n",
       "        [18, 38, 13, 70, 25],\n",
       "        [59, 42, 44, 14, 68]],\n",
       "\n",
       "       [[37, 52, 26, 25, 18],\n",
       "        [19, 15, 69, 62, 21],\n",
       "        [86, 49, 85, 61, 84],\n",
       "        [27, 44, 98, 15, 13]],\n",
       "\n",
       "       [[32, 36, 70, 30,  5],\n",
       "        [44, 12, 29,  2, 11],\n",
       "        [23, 55, 72, 22, 71],\n",
       "        [26, 78, 66, 47, 94]]])>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tf.constant(arr_3d)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811ff895",
   "metadata": {},
   "source": [
    "convert tensor object to numpy :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "03d84566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[18, 76,  5, 92,  7],\n",
       "        [17, 66, 65, 50, 25],\n",
       "        [18, 38, 13, 70, 25],\n",
       "        [59, 42, 44, 14, 68]],\n",
       "\n",
       "       [[37, 52, 26, 25, 18],\n",
       "        [19, 15, 69, 62, 21],\n",
       "        [86, 49, 85, 61, 84],\n",
       "        [27, 44, 98, 15, 13]],\n",
       "\n",
       "       [[32, 36, 70, 30,  5],\n",
       "        [44, 12, 29,  2, 11],\n",
       "        [23, 55, 72, 22, 71],\n",
       "        [26, 78, 66, 47, 94]]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a154c7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = 7\n",
      "\n",
      "\n",
      "Before adding 7 : \n",
      "\n",
      "tf.Tensor(\n",
      "[[[18 76  5 92  7]\n",
      "  [17 66 65 50 25]\n",
      "  [18 38 13 70 25]\n",
      "  [59 42 44 14 68]]\n",
      "\n",
      " [[37 52 26 25 18]\n",
      "  [19 15 69 62 21]\n",
      "  [86 49 85 61 84]\n",
      "  [27 44 98 15 13]]\n",
      "\n",
      " [[32 36 70 30  5]\n",
      "  [44 12 29  2 11]\n",
      "  [23 55 72 22 71]\n",
      "  [26 78 66 47 94]]], shape=(3, 4, 5), dtype=int64)\n",
      "\n",
      "After adding 7 : \n",
      "\n",
      "tf.Tensor(\n",
      "[[[ 25  83  12  99  14]\n",
      "  [ 24  73  72  57  32]\n",
      "  [ 25  45  20  77  32]\n",
      "  [ 66  49  51  21  75]]\n",
      "\n",
      " [[ 44  59  33  32  25]\n",
      "  [ 26  22  76  69  28]\n",
      "  [ 93  56  92  68  91]\n",
      "  [ 34  51 105  22  20]]\n",
      "\n",
      " [[ 39  43  77  37  12]\n",
      "  [ 51  19  36   9  18]\n",
      "  [ 30  62  79  29  78]\n",
      "  [ 33  85  73  54 101]]], shape=(3, 4, 5), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "#adds x to each element of tensor\n",
    "\n",
    "# x = input()\n",
    "x = 7\n",
    "print(\"x = {}\\n\\n\".format(x))\n",
    "\n",
    "print(\"Before adding {} : \\n\".format(x))\n",
    "print(tensor, end='\\n\\n')\n",
    "tensor_add_1 = tf.add(tensor , x)\n",
    "\n",
    "print(\"After adding {} : \\n\".format(x))\n",
    "print(tensor_add_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e57914",
   "metadata": {},
   "source": [
    "reshape a tensor :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "25c072a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before reshape : \n",
      "[[[ 25  83  12  99  14]\n",
      "  [ 24  73  72  57  32]\n",
      "  [ 25  45  20  77  32]\n",
      "  [ 66  49  51  21  75]]\n",
      "\n",
      " [[ 44  59  33  32  25]\n",
      "  [ 26  22  76  69  28]\n",
      "  [ 93  56  92  68  91]\n",
      "  [ 34  51 105  22  20]]\n",
      "\n",
      " [[ 39  43  77  37  12]\n",
      "  [ 51  19  36   9  18]\n",
      "  [ 30  62  79  29  78]\n",
      "  [ 33  85  73  54 101]]]\n",
      "\n",
      "shape before reshape : (3, 4, 5)\n",
      "\n",
      "\n",
      "After reshape : \n",
      "[[ 25  83  12  99  14  24  73  72  57  32  25  45  20  77  32  66  49  51\n",
      "   21  75]\n",
      " [ 44  59  33  32  25  26  22  76  69  28  93  56  92  68  91  34  51 105\n",
      "   22  20]\n",
      " [ 39  43  77  37  12  51  19  36   9  18  30  62  79  29  78  33  85  73\n",
      "   54 101]]\n",
      "\n",
      "shape after reshape : (3, 20)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t = tensor_add_1\n",
    "\n",
    "print( ('Before reshape : \\n{}').format(t.numpy() ))\n",
    "print('\\nshape before reshape : {}\\n\\n'.format(t.get_shape() ) )\n",
    "\n",
    "t = tf.reshape(tensor = t, shape=[3 , 20])\n",
    "\n",
    "print( ('After reshape : \\n{}').format(t.numpy() ))\n",
    "print('\\nshape after reshape : {}\\n\\n'.format(t.get_shape() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c936dac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before reshape : \n",
      "[[[ 25  83  12  99  14]\n",
      "  [ 24  73  72  57  32]\n",
      "  [ 25  45  20  77  32]\n",
      "  [ 66  49  51  21  75]]\n",
      "\n",
      " [[ 44  59  33  32  25]\n",
      "  [ 26  22  76  69  28]\n",
      "  [ 93  56  92  68  91]\n",
      "  [ 34  51 105  22  20]]\n",
      "\n",
      " [[ 39  43  77  37  12]\n",
      "  [ 51  19  36   9  18]\n",
      "  [ 30  62  79  29  78]\n",
      "  [ 33  85  73  54 101]]]\n",
      "\n",
      "shape before reshape : (3, 4, 5)\n",
      "\n",
      "\n",
      "After reshape : \n",
      "[[[[ 25  83  12]\n",
      "   [ 99  14  24]]\n",
      "\n",
      "  [[ 73  72  57]\n",
      "   [ 32  25  45]]\n",
      "\n",
      "  [[ 20  77  32]\n",
      "   [ 66  49  51]]\n",
      "\n",
      "  [[ 21  75  44]\n",
      "   [ 59  33  32]]\n",
      "\n",
      "  [[ 25  26  22]\n",
      "   [ 76  69  28]]]\n",
      "\n",
      "\n",
      " [[[ 93  56  92]\n",
      "   [ 68  91  34]]\n",
      "\n",
      "  [[ 51 105  22]\n",
      "   [ 20  39  43]]\n",
      "\n",
      "  [[ 77  37  12]\n",
      "   [ 51  19  36]]\n",
      "\n",
      "  [[  9  18  30]\n",
      "   [ 62  79  29]]\n",
      "\n",
      "  [[ 78  33  85]\n",
      "   [ 73  54 101]]]]\n",
      "\n",
      "shape after reshape : (2, 5, 2, 3)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t = tensor_add_1\n",
    "\n",
    "print( ('Before reshape : \\n{}').format(t.numpy() ))\n",
    "print('\\nshape before reshape : {}\\n\\n'.format(t.get_shape() ) )\n",
    "\n",
    "# t = tf.reshape(tensor = t, shape=[2,2,3,5])\n",
    "# t = tf.reshape(tensor = t, shape=[5,3,2,2])\n",
    "t = tf.reshape(tensor = t, shape=[2,5,2,3])\n",
    "\n",
    "print( ('After reshape : \\n{}').format(t.numpy() ))\n",
    "print('\\nshape after reshape : {}\\n\\n'.format(t.get_shape() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7b2433c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_sys',\n",
       " 'boston_housing',\n",
       " 'cifar10',\n",
       " 'cifar100',\n",
       " 'fashion_mnist',\n",
       " 'imdb',\n",
       " 'mnist',\n",
       " 'reuters']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tf.keras.datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73057b79",
   "metadata": {},
   "source": [
    "observing fashion mnist dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e2468cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "054a1f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c825fd3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "29515/29515 [==============================] - 0s 2us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26421880/26421880 [==============================] - 8s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "5148/5148 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4422102/4422102 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(training_image, training_label), (testing_image, testing_label) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6d810c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of dimensions of training samples : 3\n",
      "dimensions of training samples : (60000, 28, 28)\n",
      "\n",
      "\n",
      "number of dimensions of testing samples : 3\n",
      "dimensions of testing samples : (10000, 28, 28)\n",
      "\n",
      "\n",
      "number of dimensions of testing  labels : 1\n",
      "dimensions of testing labels : (25000,)\n",
      "\n",
      "\n",
      "number of dimensions of testing  labels : 1\n",
      "dimensions of testing labels : (25000,)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"number of dimensions of training samples : {}\".format(training_image.ndim))\n",
    "print(\"dimensions of training samples : {}\\n\\n\".format(training_image.shape))\n",
    "\n",
    "print(\"number of dimensions of testing samples : {}\".format(testing_image.ndim))\n",
    "print(\"dimensions of testing samples : {}\\n\\n\".format(testing_image.shape))\n",
    "\n",
    "print(\"number of dimensions of testing  labels : {}\".format(training_label.ndim))\n",
    "print(\"dimensions of testing labels : {}\\n\\n\".format(training_label.shape))\n",
    "\n",
    "print(\"number of dimensions of testing  labels : {}\".format(testing_label.ndim))\n",
    "print(\"dimensions of testing labels : {}\\n\\n\".format(testing_label.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "71e3e049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f2d80374dc0>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the first image from the training dataset\n",
    "import matplotlib.pyplot as plt \n",
    "import random\n",
    "\n",
    "id = random.randint(0,100)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(training_image[id])\n",
    "plt.colorbar()\n",
    "# plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23b1eaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
